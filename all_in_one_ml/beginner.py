# -*- coding: utf-8 -*-
"""ml_package_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1slXIOwuXRSfAQpsAAsGs1DIkqMU3hHYZ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from sklearn.impute import SimpleImputer
from keras.models import Sequential
from keras.layers import Dense
import seaborn as sns
import matplotlib.pyplot as plt

def read_dataset(param):
  y_var = param[1]
  path = param[0]
  ind = param[2]
  if ind ==' ':
    df = pd.read_csv(path)
    y = df[y_var]
    x = df.drop(columns=y_var)
    print(df.head())
    return df,x,y

  else:
    df = pd.read_csv(path,index_col=ind)
    y = df[y_var]
    x = df.drop(columns=y_var)
    print(df.head())
    return df,x,y

def one_hot(x,y,cat=False,exc=False,onlyoutcome=False,onlyx=False):
    if cat =='~':
      for j in x.columns:
        onehot = pd.get_dummies(x[j],prefix=j)
        x = x.drop(columns=[j])
        x = pd.concat([x,onehot],axis=1)
      y = pd.get_dummies(y)
      return x,y

    elif exc == True:
      col = x.columns
      col1 = list(col)
      for i in cat:
        col1.remove(i)
      for j in col1:
        onehot = pd.get_dummies(x[j],prefix=j)
        x = x.drop(columns=[j])
        x = pd.concat([x,onehot],axis=1)
      y = pd.get_dummies(y)
      return x,y
    
    elif onlyoutcome == True:
      y = pd.get_dummies(y)
      return y

    elif onlyx == True:
      for j in x.columns:
        onehot = pd.get_dummies(x[j],prefix=j)
        x = x.drop(columns=[j])
        x = pd.concat([x,onehot],axis=1)
      return x
    else:
      print('----')
      for i in cat:
        onehot = pd.get_dummies(x[i],prefix=i)
        x = x.drop(columns=[i])
        x = pd.concat([x,onehot],axis=1)
      y = pd.get_dummies(y)
      return x,y

def split_dataset(x,y,size,state):
  x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=size,random_state=state)
  print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)
  return x_train,x_test,y_train,y_test

def build_compile_fit_model(x,y,type,epo):
  if type == 'classification':
    x = np.asarray(x).astype('float32')
    model = Sequential()
    model.add(Dense(10,activation='relu',input_shape=(x.shape[1],)))
    model.add(Dense(10,activation='relu'))
    model.add(Dense(y.shape[1],activation='softmax'))
    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
    History = model.fit(x,y,epochs=epo,validation_split=0.2)
    return model,History
  elif type == 'regression':
    model = Sequential()
    model.add(Dense(10,activation='relu',input_shape=(x.shape[1],)))
    model.add(Dense(10,activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
    History = model.fit(x,y,epochs=epo,validation_split=0.2)
    return model,History

def get_accuracy(x,y,model): 
  model.evaluate(x,y)

def get_plot(x,type):
  if type == 'correlation':
    cora = x.corr()
    sns.heatmap(cora)

def loss_vs_valloss(model,History,epochs):
  loss_train = History.history['loss']
  loss_val = History.history['val_loss']
  epochs = range(epochs)
  plt.plot(epochs, loss_train, 'g', label='Training loss')
  plt.plot(epochs, loss_val, 'b', label='validation loss')
  plt.title('Training and Validation loss')
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.legend()
  plt.show()

def accuracy_vs_valaccuracy(model,History,epochs):
  acc_train = History.history['accuracy']
  acc_val = History.history['val_accuracy']
  epochs = range(epochs)
  plt.plot(epochs, acc_train, 'g', label='Training accuracy')
  plt.plot(epochs, acc_val, 'b', label='validation accuracy')
  plt.title('Training and Validation accuracy')
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.legend()
  plt.show()